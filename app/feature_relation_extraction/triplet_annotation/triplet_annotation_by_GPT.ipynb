{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input sentences\n",
    "from pandas import read_json, Series\n",
    "CTD_RE_V1 = read_json('../../label_studio/export/CTD_RE_v1.json').set_index('id')\n",
    "sentences = Series(data = [row['text'] for row in CTD_RE_V1.data], index=CTD_RE_V1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 2000 sentences as train set for finetuning llama models\n",
    "sample = sentences.sample(n=2000, random_state=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the ids of sampled train set\n",
    "from csv import writer\n",
    "with open('data/random_2000/sampled_train_ids.csv', 'w', newline='') as outfile:\n",
    "     wr = writer(outfile)\n",
    "     wr.writerow(list(sample.index.values))\n",
    "     outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 100 other sentences for inference\n",
    "import random\n",
    "random.seed(10)\n",
    "sampled_test_ids = random.sample([i for i in sentences.index if i not in sample.index], 100)\n",
    "\n",
    "# save the ids of sampled test set\n",
    "with open('data/random_2000/sampled_test_ids.csv', 'w', newline='') as outfile:\n",
    "     wr = writer(outfile)\n",
    "     wr.writerow(sampled_test_ids)\n",
    "     outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    \"\"\"Data model for an entity.\"\"\"\n",
    "    entity_name: str = Field(description = \"Entity name of the chemical compound or gene/protein\") \n",
    "    entity_type: str = Field(description = \"Indicates the type of the entity, must be \\\"Chemical\\\" or \\\"Gene/Protein\\\"\")\n",
    "\n",
    "class Relation(BaseModel):\n",
    "    \"\"\"Data model for a relation.\"\"\"\n",
    "    subject_entity: Entity = Field(description = \"Entity that decribes the subject of the relation and the entity should be chemical compound or gene/protein\")\n",
    "    relation_phrase: str = Field(description = \"Relation phrase which must be one of the four relations: increases, decreases, affects and binds\")\n",
    "    object_entity: Entity = Field(description = \"Entity that decribes the object of the relation and the entity should be chemical compound or gene/protein\")\n",
    "\n",
    "class Results(BaseModel):\n",
    "    \"\"\"Data model for a annotation result.\"\"\"\n",
    "    relations: List[Relation] = Field(description = \"Relationships between entities that decribe scientific observations and hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "\n",
    "    # task 21001\n",
    "    {   \n",
    "        'text': 'Tetrandrine triggered LC3B expression and induced autophagy in CAL 27 cells.',\n",
    "        'relations': [{\"subject_entity\": {'entity_name':'Tetrandrine', 'entity_type':'Chemical'},\n",
    "                       \"relation_phrase\": 'increases',\n",
    "                       \"object_entity\": {'entity_name':'LC3B', 'entity_type':'Gene/Protein'}}]\n",
    "    },\n",
    "\n",
    "    # task 21002\n",
    "    {\n",
    "        'text': 'Tetrandrine and cepharanthine induce apoptosis through caspase cascade regulation, cell cycle arrest, MAPK activation and PI3K/Akt/mTOR signal modification in glucocorticoid resistant human leukemia Jurkat T cells.',\n",
    "        'relations': [{\"subject_entity\": {'entity_name':'Tetrandrine', 'entity_type':'Chemical'},\n",
    "                       \"relation_phrase\": 'decreases',\n",
    "                       \"object_entity\": {'entity_name':'mTOR', 'entity_type':'Gene/Protein'}},\n",
    "                       {\"subject_entity\": {'entity_name':'cepharanthine', 'entity_type':'Chemical'},\n",
    "                       \"relation_phrase\": 'decreases',\n",
    "                       \"object_entity\": {'entity_name':'mTOR', 'entity_type':'Gene/Protein'}}]\n",
    "    },\n",
    "\n",
    "    # task 21011\n",
    "    {\n",
    "        'text': 'CONCLUSIONS: These findings are consistent with the idea that theophylline suppresses the production of proinflammatory cytokines via inhibition of NF-kappaB activation through preservation of the IkappaBalpha protein in monocytes/macrophages and T cells.',\n",
    "        'relations': [{\"subject_entity\": {'entity_name':'theophylline', 'entity_type':'Chemical'},\n",
    "                       \"relation_phrase\": 'affacts',\n",
    "                       \"object_entity\": {'entity_name':'IkappaBalpha', 'entity_type':'Gene/Protein'}}]\n",
    "    },\n",
    "\n",
    "    # task 21052\n",
    "    {\n",
    "        'text': 'We then examined the activity of urokinase-type plasminogen activator (uPA), the rate-limiting enzyme in the TGF-beta2 activation cascade, in t-flavanone-treated human keratinocytes.',\n",
    "        'relations': [{\"subject_entity\": {'entity_name':'TGF-beta2', 'entity_type':'Gene/Protein'},\n",
    "                       \"relation_phrase\": 'binds',\n",
    "                       \"object_entity\": {'entity_name':'urokinase-type plasminogen activator', 'entity_type':'Gene/Protein'}}]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert examples to previously defined pydantic data model\n",
    "def toFewShot(example):\n",
    "    fewshot_example = dict()\n",
    "    fewshot_example['input text'] = example['text']\n",
    "    fewshot_example['output'] = Results.model_validate({\"relations\": example[\"relations\"]}).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "    return fewshot_example\n",
    "\n",
    "fewshot_examples = [toFewShot(example) for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate prompt with fewshot examples\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"input text\", \"output\"], template=\"Input text: {input text}\\nOutput:\\n{output}\")\n",
    "#print(example_prompt.format(**fewshot_examples[0]))\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Results)\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=fewshot_examples,\n",
    "    example_prompt=example_prompt, \n",
    "    prefix=\"\"\"Given an input text sentence, extract the fact relations in the input text.\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    suffix=\"\", \n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(prompt.format().replace(\"{\", \"{{\").replace(\"}\", \"}}\") + \"\\n\\nInput text: {input}\\nOutput:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "program = OpenAIPydanticProgram.from_defaults(\n",
    "    output_cls=Results,\n",
    "    llm=OpenAI(model=\"gpt-4\"),\n",
    "    prompt_template_str=prompt.format().replace(\"{\", \"{{\").replace(\"}\", \"}}\") + \"\\n\\nInput text:: {input}\\nOutput:\\n\",\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate the train sentences and save output as json files\n",
    "# 2000 files with 3h40m\n",
    "from tqdm import tqdm\n",
    "from json import dumps\n",
    "for task_id in tqdm(sample.index):\n",
    "    with open(\"data/random_2000/output_gpt/task\" + str(task_id)+\"_gpt_annotation.json\", \"w\") as outfile:\n",
    "        outfile.write(dumps(program(input = sentences[task_id]).model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate the train sentences and save output as json files\n",
    "from langchain_anthropic.experimental import ChatAnthropicTools\n",
    "from tqdm import tqdm\n",
    "from json import dumps\n",
    "# load train and test sentence ids\n",
    "from csv import reader\n",
    "file = open(\"data/random_2000/sampled_train_ids.csv\", \"r\")\n",
    "sampled_train_ids = list(map(int, list(reader(file, delimiter=\",\"))[0]))\n",
    "file.close()\n",
    "\n",
    "# generate results for test sample\n",
    "file = open(\"data/random_2000/sampled_test_ids.csv\", \"r\")\n",
    "sampled_test_ids = list(map(int, list(reader(file, delimiter=\",\"))[0]))\n",
    "file.close()\n",
    "\n",
    "chain = ChatAnthropicTools(model=\"claude-3-opus-20240229\").with_structured_output(Results)\n",
    "for task_id in tqdm(sampled_train_ids):\n",
    "    with open(\"data/random_2000/output_claude/task\" + str(task_id)+\"_claude_annotation.json\", \"w\") as outfile:\n",
    "        output = chain.invoke(prompt.format().replace(\"{\", \"{{\").replace(\"}\", \"}}\") + \"\\n\\n### Input text: \" + sentences[task_id] + \"\\n### Output:\\n\")\n",
    "        outfile.write(dumps(output, indent=4))\n",
    "        outfile.close()\n",
    "\n",
    "# annotate the test sentences and save output as json files\n",
    "for task_id in tqdm(sampled_test_ids):\n",
    "    with open(\"data/random_2000/test_sample_output/output_claude/task\" + str(task_id)+\"_claude_annotation.json\", \"w\") as outfile:\n",
    "        output = chain.invoke(prompt.format().replace(\"{\", \"{{\").replace(\"}\", \"}}\") + \"\\n\\n### Input text: \" + sentences[task_id] + \"\\n### Output:\\n\")\n",
    "        outfile.write(dumps(output, indent=4))\n",
    "        outfile.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
