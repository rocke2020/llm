{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama finetuned by gpt 500 samples is very bad but 2000 samples are good.\n",
    "# treat gpt annotation as gold standard and compare llama with gpt 2000 samples.\n",
    "# precision    0.539507\n",
    "# recall       0.686333\n",
    "# f1           0.60\n",
    "\n",
    "# load input text sentences\n",
    "from pandas import read_json, Series\n",
    "CTD_RE_V1 = read_json('../label_studio/export/CTD_RE_v1.json').set_index('id')\n",
    "sentences = Series(data = [row['text'] for row in CTD_RE_V1.data], index=CTD_RE_V1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt annotations\n",
    "from json import load\n",
    "def format_gpt_relation(relation):\n",
    "    return ((relation['subject_entity']['entity_name'], relation['subject_entity']['entity_type']),\n",
    "                            relation['relation_phrase'],\n",
    "                            (relation['object_entity']['entity_name'], relation['object_entity']['entity_type']))\n",
    "\n",
    "def get_gpt_annotation(task_id, model_output_path):\n",
    "    with open(model_output_path + '/task' + str(task_id) + '_gpt_annotation.json') as json_file:\n",
    "        gpt_output = load(json_file)\n",
    "        gpt_annotations = [format_gpt_relation(relation) for relation in gpt_output['relations']]\n",
    "        json_file.close()\n",
    "    return list(set(gpt_annotations))\n",
    "\n",
    "# load llama_annotations\n",
    "def format_matched_string(s):\n",
    "    while s.startswith((\"'\", '\"', '(')):\n",
    "        s = s[1:]\n",
    "    while s.endswith((\"'\", '\"', ')')):\n",
    "        s = s[:-1]\n",
    "    return s\n",
    "\n",
    "from re import findall\n",
    "def get_llama_annotation(task_id, model_output_path):\n",
    "    with open(model_output_path + str(task_id) + '.txt',\"r\") as f:\n",
    "        llama_output = f.read()\n",
    "        f.close()\n",
    "    output_start_id = llama_output.find('### Extracted relations:')\n",
    "    # find pattern: (({some_text}, {some_text}), {some_text}, ({some_text}, {some_text}))\n",
    "    #triple_pattern = r\"\\(\\(([^,]+),\\s*([^,]+)\\),\\s*([^,]+),\\s*\\(([^,]+),\\s*([^,]+)\\)\\)\"\n",
    "    # find pattern: non greedy ({some_text}, {some_text}), {some_text}, ({some_text}, {some_text})\n",
    "    triple_pattern =  r\"\\(([^,]+?),\\s*([^,]+?)\\),\\s*([^,]+?),\\s*\\(([^,]+?),\\s*([^,]+?)\\)\"\n",
    "    # TODO: problem with stripping \")\" at the end of the string: TGF-beta(1\n",
    "    matches = findall(triple_pattern, llama_output[output_start_id:])\n",
    "    matches = [[format_matched_string(s) for s in match] for match in matches]\n",
    "    return list(set([((m[0], m[1]), m[2], (m[3], m[4])) for m in matches]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test sample ids\n",
    "from csv import reader\n",
    "with open(\"test_output_2000/sampled_test_ids.csv\", \"r\") as file:\n",
    "    sampled_test_ids = list(map(int, list(reader(file, delimiter=\",\"))[0]))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "task_id = sampled_test_ids[14]\n",
    "print('--- task ' + str(task_id) + ' ---')\n",
    "print(sentences[task_id])\n",
    "print('--- gpt annotation: ---')\n",
    "print(get_gpt_annotation(task_id, 'test_output_2000/gpt/gpt_annotation/'))\n",
    "print('--- llama annotation: ---')\n",
    "print(get_llama_annotation(task_id, 'test_output_2000/gpt/llama3-8b-CTD_RE_V1-finetune-r_8_la_32-checkpoint-260/'))\n",
    "\n",
    "Here, I think llama annotation is better than gpt annotation.\n",
    "--- task 22326 ---\n",
    "Obvious decrease of TGF-beta(1) was found in troglitazone(15 micromol/L) treated group compared with group stimulated with 30 mmol/L D-glucose (P<0.05).\n",
    "--- gpt annotation: ---\n",
    "[(('troglitazone', 'Chemical'), 'decreases', ('TGF-beta(1)', 'Gene/Protein'))]\n",
    "--- llama annotation: ---\n",
    "[(('troglitazone', 'Chemical'), 'decreases', ('TGF-beta(1', 'Gene/Protein')), (('D-glucose', 'Chemical'), 'increases', ('TGF-beta(1', 'Gene/Protein'))]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "def evaluate(gpt_model_output_path, llama_model_output_path, task_ids):\n",
    "    llama_annotations = []\n",
    "    gpt_annotations = []\n",
    "    intersects = []\n",
    "    for task_id in task_ids:\n",
    "        llama_annotation = get_llama_annotation(task_id, llama_model_output_path)\n",
    "        gpt_annotation = get_gpt_annotation(task_id, gpt_model_output_path)\n",
    "        llama_annotations.append(llama_annotation)\n",
    "        gpt_annotations.append(gpt_annotation)\n",
    "        intersects.append([r for r in gpt_annotation if r in llama_annotation])\n",
    "    \n",
    "    # true positive: number of relations that are in both gpt annotations and llama annotions\n",
    "    tp = np.array([len(intersects[i]) for i in range(100)])\n",
    "    # false positive: number of relations that are in llama annotations but not in gpt annotations\n",
    "    fp = np.array([len(llama_annotations[i]) - len(intersects[i]) for i in range(100)])\n",
    "    # false negative: number of relations that are in gpt annotations but not in llama annotations\n",
    "    fn = np.array([len(gpt_annotations[i]) - len(intersects[i]) for i in range(100)])\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "\n",
    "    \n",
    "    result = DataFrame({'task_id':task_ids,\n",
    "                        'gpt_annotations': gpt_annotations,\n",
    "                        'llama_annotations':llama_annotations,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1': f1})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6041268971986556\n"
     ]
    }
   ],
   "source": [
    "p = 0.539507\n",
    "r = 0.686333\n",
    "f1 = 2 * p * r / (p + r)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
